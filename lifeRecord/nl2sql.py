# lifeRecord/NL2SQL.py
import openai
from pathlib import Path
import chromadb
import chromadb.utils.embedding_functions as embedding_functions
import os
import json
import pandas as pd
from tqdm import tqdm

BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"
DB_PATH = BASE_DIR / "vectordb"

SCHEMA_FILE = DATA_DIR / "lifeRecordSchema.json"
FEWSHOT_FILE = DATA_DIR / "fewshot.jsonl"
API_KEY_FILE = DATA_DIR / "api_key.txt"

def load_api_key(api_key_path):
    with open(api_key_path, "r", encoding="utf-8") as f:
        return f.read().strip()

OPENAI_API_KEY = load_api_key(API_KEY_FILE)

def nlTosql(user_question):
    llm = openai.OpenAI(api_key=OPENAI_API_KEY)

    relevant_columns = find_relevant_columns(user_question, top_k=5)

    schema_info = generate_filtered_schema(
        input_file=SCHEMA_FILE,
        used_columns=relevant_columns,
        include_descriptions=True
    )

    fewshots_text = get_relevant_fewshots(user_question, top_k=2)

    prompt_template =   """
                        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ í•™ìƒìƒí™œê¸°ë¡ë¶€ë¥¼ ì‘ì„±í•˜ëŠ” êµì‚¬ë¥¼ ë„ì™€, í•„ìš”í•œ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •í™•íˆ ì¶”ì¶œí•˜ëŠ” ì—­í• ì„ ë§¡ê³  ìˆìŠµë‹ˆë‹¤.

                        ìƒí™œê¸°ë¡ë¶€ëŠ” ì´ˆÂ·ì¤‘Â·ê³  í•™ìƒë“¤ì˜ í•™êµìƒí™œ ì „ë°˜ì„ ê³µì‹ì ìœ¼ë¡œ ê¸°ë¡í•˜ëŠ” ë¬¸ì„œë¡œ, ëŒ€í•™ ì…ì‹œ ë° ì·¨ì—…ì— ë§¤ìš° ì¤‘ìš”í•œ í‰ê°€ ìë£Œì…ë‹ˆë‹¤.
                        ë”°ë¼ì„œ êµì‚¬ì˜ ì§ˆë¬¸ì´ë‚˜ ëª…ë ¹ì„ ì •í™•íˆ ë¶„ì„í•˜ì—¬, ì ì ˆí•œ SQLite ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

                        ---

                        **ë‹¹ì‹ ì˜ ì‘ì—… ìˆœì„œ:**
                        1. ì‚¬ìš©ì ì§ˆë¬¸ ë˜ëŠ” ëª…ë ¹ì„ ë¶„ì„í•©ë‹ˆë‹¤.
                        2. í•„ìš”í•œ ì¡°ê±´(í•™ë…„, í•™ê¸°, í™œë™ ìœ í˜•, ë™ì•„ë¦¬ëª…, ê³¼ëª©ëª… ë“±)ì„ ë‹¨ê³„ë³„ë¡œ ì¶”ì¶œí•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.
                        3. ì •í™•í•˜ê³  ì™„ì „í•œ SQLite ì¿¼ë¦¬ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

                        ---

                        **ì¿¼ë¦¬ ì‘ì„± ì‹œ ìœ ì˜ì‚¬í•­:**
                        - ë°˜ë“œì‹œ ì¿¼ë¦¬ ê²°ê³¼ì— í•™ìƒ ì •ë³´(`student.student_id`, `student.student_name`)ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
                        - í™œë™ ìœ í˜•ì„ í¬í•¨í•˜ê³  ê·¸ ìœ í˜•ì— ë”°ë¼ ì¶”ê°€ ì •ë³´ í¬í•¨:
                            - í™œë™ ìœ í˜•ì´ 'ë™ì•„ë¦¬í™œë™'ì¸ ê²½ìš° `club_name` ë° `club_description` ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
                            - ì´ ë•Œ activityì—ì„œ clubìœ¼ë¡œì˜ ì ‘ê·¼ì€ Foreign keyì¸ club_idë¥¼ í™œìš©í•©ë‹ˆë‹¤.
                        - `activity_description`(í™œë™ ì„¤ëª…)ì€ í•­ìƒ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
                        - ì§ˆë¬¸ì— íŠ¹ì • ë™ì•„ë¦¬ëª…(ì˜ˆ: 'í”¼íƒ€ê³ ë¼ìŠ¤')ì´ í¬í•¨ëœ ê²½ìš°, í•´ë‹¹ ë™ì•„ë¦¬ì— í•œì •í•´ì•¼ í•©ë‹ˆë‹¤.
                        - í™œë™ì˜ ëŒ€ìƒì´ ê°œì¸ì¸ì§€ ê·¸ë£¹ì¸ì§€ë„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.
                        - ë‚ ì§œ ì¡°ê±´ì´ ìˆëŠ” ê²½ìš°:
                            - `activity_date`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§.
                            - ì˜ˆ) 2024ë…„ 1í•™ê¸° â†’ `2024-03-01` ~ `2024-07-31` ë²”ìœ„ë¡œ ê°„ì£¼.

                        ---

                        **ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:**
                        {DATABASE_SCHEMA}

                        ---

                        **ì˜ˆì‹œ ì§ˆë¬¸ ë° ì¿¼ë¦¬:**
                        {FEWSHOTS}

                        ---

                        **ì‚¬ìš©ì ì§ˆë¬¸ ë˜ëŠ” ëª…ë ¹:**
                        {QUESTION}

                        {HINT}

                        ---

                        **ìµœì¢… ì¶œë ¥ í˜•ì‹ (JSON):**
                        {{
                        "chain_of_thought_reasoning": "ìµœì¢… SQL ì¿¼ë¦¬ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ë‹¹ì‹ ì˜ ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •",
                        "SQL": "ì‘ì„±í•œ ìµœì¢… SQLite ì¿¼ë¦¬"
                        }}

                        ìœ„ ê·œì¹™ì— ë”°ë¼ ì‹ ì¤‘í•˜ê²Œ ìƒê°ì„ ì „ê°œí•˜ê³  ì •í™•í•œ SQLì„ ì‘ì„±í•˜ì„¸ìš”.
                        """


    prompt = prompt_template.format(
        DATABASE_SCHEMA=schema_info,
        QUESTION=user_question,
        HINT="",  # í•„ìš”ì‹œ íŒíŠ¸ ì¶”ê°€ ê°€ëŠ¥
        FEWSHOTS=fewshots_text,
    )

    response = llm.chat.completions.create(
        model='gpt-4o-mini',
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    generated_text = response.choices[0].message.content
    print("LLM ì‘ë‹µ:\n", generated_text)

    import re

    try:
        # JSON ê°ì²´ ë¸”ë¡ ì¶”ì¶œ ì‹œë„
        match = re.search(r"\{.*\}", generated_text, re.DOTALL)
        if match:
            json_str = match.group(0)
            generated_dict = json.loads(json_str)
            return generated_dict
        else:
            print("JSON í˜•ì‹ ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
    except json.JSONDecodeError as e:
        print("JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        print("íŒŒì‹± ì‹œë„í•œ ë¬¸ìì—´:\n", json_str)
        return None



def find_relevant_columns(query, top_k=7):
    client = chromadb.PersistentClient(path=str(DB_PATH))

    openai_ef = embedding_functions.OpenAIEmbeddingFunction(
        api_key=OPENAI_API_KEY,
        model_name="text-embedding-3-small"
    )

    collection = client.get_or_create_collection("column_description", embedding_function=openai_ef)

    results = collection.query(
        query_texts=[query],
        n_results=top_k
    )

    print(f"\nğŸ” ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ìƒìœ„ {top_k}ê°œ ì»¬ëŸ¼:")

    best_score = 100000
    for doc, meta, score in zip(results['documents'][0], results['metadatas'][0], results['distances'][0]):
        print(f"# í…Œì´ë¸”: {meta['table']}, ì»¬ëŸ¼: {meta['column']}")
        print(f"# ì„¤ëª…: {doc.splitlines()[1]}")
        print(f"# ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f}\n")
        if score < best_score:
            best_score = score

    print(f"ìµœê³  ì ìˆ˜: {best_score:.4f}")

    return results['metadatas'][0]


def generate_filtered_schema(input_file, used_columns=None, include_descriptions=True):
    with open(input_file, "r", encoding="utf-8") as f:
        tables = json.load(f)

    output_lines = []

    if used_columns:
        used_set = set((item["table"], item["column"]) for item in used_columns)
    else:
        used_set = None

    for table in tables:
        table_name = table["table"]

        if used_set:
            table_columns = [col for col in table["column"] if (table_name, col["column_name"]) in used_set]
            if not table_columns:
                continue
        else:
            table_columns = table["column"]

        output_lines.append(f"\nğŸ“˜ í…Œì´ë¸”: {table_name}")

        for col in table_columns:
            col_name = col["column_name"]
            is_pk = col["PK"] == 1
            fk = col.get("FK")  # â† ì—¬ê¸°ë§Œ ë°©ì–´ì ìœ¼ë¡œ ìˆ˜ì •
            desc = col.get("description", None)

            # ì»¬ëŸ¼ ì •ë³´ ë¼ì¸ êµ¬ì„±
            col_line = f" - ì»¬ëŸ¼: {col_name}"
            if is_pk:
                col_line += " (PK)"
            elif isinstance(fk, dict):  # FKì¼ ë•Œë§Œ ëª…í™•í•˜ê²Œ í‘œì‹œ
                ref_table = fk.get("table")
                ref_column = fk.get("column")
                col_line += f" (FK â†’ {ref_table}.{ref_column})"

            output_lines.append(col_line)

            # ì„¤ëª… í¬í•¨
            if include_descriptions and desc:
                cleaned = desc.strip().lstrip("#").strip()
                output_lines.append(f"    â€¢ ì„¤ëª…: {cleaned}")

        output_lines.append("")  # í…Œì´ë¸” ë ê°„ê²©

    return "\n".join(output_lines)




def get_relevant_fewshots(user_question, top_k=3):
    client = chromadb.PersistentClient(path=str(DB_PATH))
    openai_ef = embedding_functions.OpenAIEmbeddingFunction(
        api_key=OPENAI_API_KEY,
        model_name="text-embedding-3-small"
    )
    collection = client.get_or_create_collection("fewshot", embedding_function=openai_ef)

    results = collection.query(
        query_texts=[user_question],
        n_results=top_k
    )

    fewshot_blocks = []
    for idx, (doc, meta) in enumerate(zip(results["documents"][0], results["metadatas"][0]), 1):
        block = f"""### ì˜ˆì œ {idx}
                        ì§ˆë¬¸: {meta['question']}
                        ê·¼ê±°: {meta['evidence']}
                        SQL:
                        {meta['SQL']}"""
        fewshot_blocks.append(block)

    return "\n\n".join(fewshot_blocks)

#if __name__ == "__main__":
#    question = "2024ë…„ 1í•™ê¸° ìˆ˜í•™ ë™ì•„ë¦¬ì¸ í”¼íƒ€ê³ ë¼ìŠ¤ì— í™œë™í•œ ì´ì›ì • í•™ìƒì˜ í™œë™ì„ ë°”íƒ•ìœ¼ë¡œ ìƒê¸°ë¶€ë¥¼ ì‘ì„±í•´ì¤˜"
#    result = nlTosql(question)